# AI Business Analyst — Система автоматической генерации бизнес-документации

Интеллектуальный помощник бизнес-аналитика для автоматического сбора требований и генерации структурированных документов (BRD, Use Case, User Stories) с диаграммами PlantUML.

##  Описание проекта

Это веб-приложение на Streamlit, которое помогает бизнес-аналитикам собирать требования к проекту через диалог с ИИ и автоматически генерировать:

- **BRD (Business Requirements Document)** — структурированный документ бизнес-требований
- **Use Case** — описание сценариев использования системы
- **User Stories** — пользовательские истории
- **PlantUML диаграммы** — детальные activity диаграммы процессов
- **PDF документ** — объединенный PDF со всеми документами

Система использует LLM (Gemma через Ollama) для понимания контекста, извлечения информации и генерации документации на русском языке.

##  Основные возможности

- **Интеллектуальный диалог**: Бот задает вопросы и понимает свободную форму ввода
- **Два режима работы**: Свободный диалог и структурированная форма
- **Автозаполнение**: В режиме структурированной формы можно использовать тестовые сценарии
- **Аналитический режим**: После генерации документов можно задавать вопросы о проекте
- **Визуализация прогресса**: Показ заполненных полей и текущего состояния
- **Экспорт документов**: Скачивание отдельных документов или общего PDF

##  Структура проекта

```
ai_ba_agent/
├── app/
│   ├── main.py                          # Streamlit UI и основной интерфейс
│   ├── config.py                        # Конфигурация проекта
│   ├── core/
│   │   ├── intelligent_dialog_manager.py  # Умный диалог с ИИ
│   │   ├── dialog_manager.py            # Структурированный диалог
│   │   ├── llm_engine.py                # Движок для работы с LLM (Ollama/Transformers)
│   │   ├── orchestrator.py              # Координация генерации документов
│   │   ├── prompt_templates.py          # Шаблоны промптов для LLM
│   │   └── templates/                   # Markdown шаблоны документов
│   ├── generators/
│   │   ├── brd_generator.py             # Генератор BRD
│   │   ├── usecase_generator.py         # Генератор Use Case
│   │   ├── userstories_generator.py     # Генератор User Stories
│   │   ├── plantuml_generator.py        # Генератор PlantUML кода
│   │   └── pdf_generator.py             # Генератор PDF документов
│   └── utils/
│       ├── state.py                     # Управление состоянием диалога
│       ├── plantuml_renderer.py         # Рендеринг PlantUML в PNG
│       ├── markdown_cleaner.py          # Очистка markdown
│       ├── auto_filler.py               # Автозаполнение форм
│       └── logger.py                    # Логирование
├── models/
│   ├── model_config.json                # Конфигурация LLM модели
│   └── cache/                           # Кэш моделей (если используется Transformers)
├── libs/
│   └── plantuml.jar                     # JAR файл для рендеринга PlantUML
├── scenarios/                           # Тестовые сценарии для автозаполнения
├── docs/                                # Документация и примеры
├── requirements.txt                     # Python зависимости
└── run.sh                               # Скрипт запуска приложения
```

##  Требования и установка

### Необходимое ПО

1. **Python 3.10+**
   ```bash
   python3 --version  # Должно быть 3.10 или выше
   ```

2. **Ollama** (для работы с LLM моделью)
   - Скачать с [ollama.ai](https://ollama.ai)
   - Установить и запустить Ollama сервер
   - Скачать модель Gemma (текущая модель по умолчанию, ~5GB):
     ```bash
     ollama pull gemma:latest
     ```
   - Проверить, что модель установлена:
     ```bash
     ollama list
     ```
   - **Текущая модель**: `gemma:latest` (Gemma 2B/7B, ~5GB)
   - **Альтернативные модели**:
     - `qwen2.5:14b` — более мощная модель (~8.5GB)
     - `qwen2.5:7b` — средний вариант (~4.7GB)
     - `llama3.1:8b` — популярная альтернатива

3. **Java 17+** (для рендеринга PlantUML диаграмм)
   - На macOS с Homebrew:
     ```bash
     brew install openjdk@17
     ```
   - На Linux (Ubuntu/Debian):
     ```bash
     sudo apt-get install openjdk-17-jdk
     ```
   - Проверить установку:
     ```bash
     java -version
     ```

4. **PlantUML JAR файл**
   - Файл `libs/plantuml.jar` уже включен в проект
   - Если его нет, скачайте с [plantuml.com](https://plantuml.com/download)

### Установка зависимостей

1. **Клонируйте репозиторий:**
   ```bash
   git clone https://github.com/shaken02/AIBusinessAnalyst_Forte.git
   cd AIBusinessAnalyst_Forte/ai_ba_agent
   ```

2. **Создайте виртуальное окружение:**
   ```bash
   python3.10 -m venv venv
   ```
   Это создаст папку `venv` внутри директории `ai_ba_agent`.

3. **Активируйте виртуальное окружение:**
   ```bash
   source venv/bin/activate
   ```
   - На Windows: `venv\Scripts\activate`
   - На Linux/macOS: `source venv/bin/activate`

4. **Обновите pip:**
   ```bash
   pip install --upgrade pip
   ```

5. **Установите зависимости:**
   ```bash
   pip install -r requirements.txt
   ```

## ▶️ Запуск приложения

### Способ 1: Использование скрипта (рекомендуется)

```bash
cd AIBusinessAnalyst/ai_ba_agent
./run.sh
```

### Способ 2: Ручной запуск

```bash
cd ai_ba_agent
source venv/bin/activate
export PYTHONPATH="${PWD}:${PYTHONPATH:-}"
export STREAMLIT_BROWSER_GATHER_USAGE_STATS=0
streamlit run app/main.py --server.headless true --server.port 8501
```

### После запуска

Приложение откроется в браузере по адресу: **http://localhost:8501**

##  Как работать с приложением

### Режим 1: Свободный диалог (Интеллектуальный)

1. **Выберите режим**: В сайдбаре выберите "Интеллектуальный диалог"
2. **Начните разговор**: После приветствия нажмите кнопку "Начать разговор"
3. **Отвечайте на вопросы**: Бот будет задавать вопросы о вашем проекте
4. **Можно писать свободно**: Вы можете предоставлять информацию частями или сразу всю
5. **Проверяйте прогресс**: В сайдбаре видно, какие поля заполнены
6. **Генерация документов**: Когда все поля заполнены, появится кнопка "Сгенерировать отчет"
7. **Аналитический режим**: После генерации можно задавать вопросы о проекте

### Режим 2: Структурированная форма

1. **Выберите режим**: В сайдбаре выберите "Структурированная форма"
2. **Заполните поля**: Заполните все поля в сайдбаре вручную
3. **Автозаполнение (опционально)**: Можно использовать кнопку "Автозаполнить из сценария" для тестирования
4. **Генерация**: Нажмите "Сгенерировать отчет" когда все поля заполнены

### Сброс диалога

- Нажмите кнопку "Сбросить диалог" в сайдбаре для очистки всех данных и начала заново

##  Поля, которые собираются

Приложение собирает следующие данные о проекте:

1. **Описание** — описание продукта/решения
2. **Проблема** — какую проблему решает продукт
3. **Цель** — ключевая цель инициативы
4. **Стейкхолдеры** — основные заинтересованные стороны
5. **Роли** — роли/персоны в процессе
6. **В рамках** — что входит в проект
7. **Вне рамок** — что исключено из проекта
8. **KPI** — ключевые метрики успеха
9. **Бизнес-правила** — важные правила/политики
10. **Ограничения** — технические/организационные ограничения
11. **Риски** — основные риски проекта
12. **Допущения** — зафиксированные допущения
13. **Нефункциональные требования** — производительность, безопасность, UX
14. **Описание процесса** — ключевые шаги процесса (используется для PlantUML)

##  Что можно делать

-  Предоставлять информацию свободной формой или структурированно
-  Отвечать на вопросы по частям или все сразу
-  Редактировать поля в сайдбаре после заполнения
-  Задавать вопросы боту (например, "С чего начать?", "Что осталось заполнить?")
-  После генерации документов задавать аналитические вопросы о проекте
-  Скачивать документы по отдельности или общим PDF
-  Использовать автозаполнение из сценариев для тестирования
-  Переключаться между режимами работы

##  Что нельзя делать

-  Генерировать документы до заполнения всех полей
-  Использовать нецензурную лексику в описании проекта (может повлиять на качество генерации)
-  Заполнять поля специальными символами или пустыми значениями
-  Запускать несколько экземпляров приложения одновременно на одном порту
-  Удалять файл `libs/plantuml.jar` (нужен для генерации диаграмм)
-  Менять структуру директорий без обновления путей в коде

##  Настройки

### Настройка модели LLM

Модель настраивается в файле `models/model_config.json`:

```json
{
  "provider": "ollama",
  "model_name": "gemma:latest",
  "ollama_api_url": "http://localhost:11434/api/generate",
  "temperature": 0.2,
  "top_p": 0.9,
  "max_new_tokens": 2048
}
```

**Доступные модели Ollama:**
- `gemma:latest` (текущая, ~5GB)
- `qwen2.5:14b` (более мощная, ~8.5GB)
- `llama3.1:8b` (альтернатива)

Для смены модели:
1. Убедитесь, что модель скачана: `ollama pull <model_name>`
2. Обновите `model_name` в `models/model_config.json`
3. Перезапустите приложение

### Переменные окружения

- `AI_BA_LOG_LEVEL` — уровень логирования (DEBUG, INFO, WARNING, ERROR), по умолчанию INFO
- `STREAMLIT_BROWSER_GATHER_USAGE_STATS` — статистика использования Streamlit (0 = отключено)

##  Решение проблем

### Приложение не запускается

- **Проверьте Python версию**: Должна быть 3.10+
- **Проверьте виртуальное окружение**: Должно быть активировано
- **Проверьте зависимости**: `pip install -r requirements.txt`
- **Проверьте Ollama**: Должен быть запущен (`ollama serve` или автоматически)

### Модель не отвечает

- **Проверьте Ollama**: `ollama list` — модель должна быть в списке
- **Проверьте доступность API**: `curl http://localhost:11434/api/generate`
- **Проверьте модель в config**: Должна совпадать с установленной

### PlantUML не генерируется

- **Проверьте Java**: `java -version` — должна быть версия 17+
- **Проверьте plantuml.jar**: Должен быть в `libs/plantuml.jar`
- **Проверьте логи**: В консоли могут быть ошибки Java

### Диаграммы пустые или недетальные

- Это может быть связано с качеством модели или описанием процесса
- Попробуйте более детально описать процесс в поле "Описание процесса"
- Убедитесь, что описание процесса содержит конкретные шаги

### Порт занят

- Измените порт в команде запуска: `--server.port 8502`
- Или остановите процесс на порту: `lsof -ti:8501 | xargs kill -9`

##  Дополнительная информация

### Примеры использования

В директории `scenarios/` есть примеры сценариев, которые можно использовать для автозаполнения:
- `scenario_01_loyalty.txt` — программа лояльности
- `scenario_02_payment.txt` — мобильное приложение для платежей
- `scenario_03_savings.txt` — система накоплений

### Структура генерируемых документов

- **BRD**: Следует шаблону из `app/core/templates/brd_template.md`
- **Use Case**: Следует шаблону из `app/core/templates/usecase_template.md`
- **User Stories**: Следует шаблону из `app/core/templates/userstories_template.md`
- **PlantUML**: Генерирует activity диаграмму на основе описания процесса

### Архитектура

- **Frontend**: Streamlit (веб-интерфейс)
- **Backend**: Python 3.10+
- **LLM Engine**: Ollama (локальный) или Transformers (опционально)
- **PDF Generation**: ReportLab
- **Diagram Rendering**: PlantUML через Java

##  Лицензия

Проект создан в рамках хакатона ForteBank AI Forte Case.

##  Авторы

Разработано командой для задачи автоматизации бизнес-анализа.

---

**Важно**: Убедитесь, что Ollama сервер запущен перед использованием приложения. Модель Gemma занимает ~5GB дискового пространства.
